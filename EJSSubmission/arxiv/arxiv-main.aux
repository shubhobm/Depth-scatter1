\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\citation{ref:JNonpara95201_MottonenOja95}
\citation{ref:Test991_Locantoreetal,ref:OjaBook10,ref:JASA151658_WangPengLi}
\citation{ref:SPL12765_Taskinenetal}
\citation{ref:Biometrika14673_MagyarTyler}
\citation{ref:AoS87234_Tyler}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{1}{section.1}\protected@file@percent }
\newlabel{Sec:Introduction}{{1}{1}{Introduction}{section.1}{}}
\newlabel{eq:GSign}{{1}{1}{Introduction}{equation.1.1}{}}
\citation{ref:DIMACS061_Serfling,ref:AoS00461_ZuoSerfling}
\citation{LiuPareliusSingh99,ref:DIMACS061_Serfling}
\newlabel{eqn:rank}{{2}{2}{Introduction}{equation.1.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces  An illustrative bivariate scatter plot in the top left panel where the outliers are identified with red circles, and generalized signs from the same data (black points on the unit radius circle, outliers are red points) in the other panels. In the top right (bottom left, bottom right) panel, weighted signs from the same data with weights obtained using Mahalanobis depth (Tukey depth, projection depth respectively) are presented as green triangles (outliers are identified by blue triangles). \relax }}{3}{figure.caption.1}\protected@file@percent }
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:Fig1}{{1}{3}{An illustrative bivariate scatter plot in the top left panel where the outliers are identified with red circles, and generalized signs from the same data (black points on the unit radius circle, outliers are red points) in the other panels. In the top right (bottom left, bottom right) panel, weighted signs from the same data with weights obtained using Mahalanobis depth (Tukey depth, projection depth respectively) are presented as green triangles (outliers are identified by blue triangles). \relax }{figure.caption.1}{}}
\citation{ref:JASA96862_Chaudhuri,ref:Biometrika48414_Haldane,ref:AoS97435_Koltchinskii}
\citation{ref:AoS17591_Cardotetal_Median_HilbertSpace,ref:AoS141203_ChakrabortyChaudhuri_Banach_Quantile,ref:Bernoulli152308_Minsker_Median_Banach}
\@writefile{toc}{\contentsline {section}{\numberline {2}The Weighted Spatial Median}{4}{section.2}\protected@file@percent }
\newlabel{Sec:WSQuantiles}{{2}{4}{The Weighted Spatial Median}{section.2}{}}
\newlabel{eq:WeightedQuantile}{{3}{4}{The Weighted Spatial Median}{equation.2.3}{}}
\citation{ref:AoS891631_Haberman,ref:AoS921514_Niemiro}
\citation{ref:AoS921514_Niemiro}
\citation{ref:AoS891631_Haberman}
\citation{ref:CBose_AoS05414}
\citation{StatPaper18}
\newlabel{Thm:WSMedian}{{2.1}{5}{}{Theorem.2.1}{}}
\@writefile{toc}{\contentsline {paragraph}{Remark.}{5}{section*.2}\protected@file@percent }
\citation{ref:Fangetal90_Book}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}Asymptotic efficiency of weighted spatial median}{6}{subsection.2.1}\protected@file@percent }
\newlabel{Cor:ARE}{{2.2}{6}{}{Theorem.2.2}{}}
\citation{ref:JASA151658_WangPengLi}
\citation{ref:SPL12765_Taskinenetal}
\citation{ref:JASA151658_WangPengLi}
\citation{ref:DIMACS061_Serfling,ref:AoS00461_ZuoSerfling}
\newlabel{Cor:Elliptic_ARE}{{2.4}{7}{}{Theorem.2.4}{}}
\newlabel{eqn:CorElliptic_ARE_eqn}{{4}{7}{}{equation.2.4}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}Examples of affine invariant weights}{7}{subsection.2.2}\protected@file@percent }
\newlabel{eq:Peripherality}{{5}{7}{Examples of affine invariant weights}{equation.2.5}{}}
\citation{ref:AoS112852_Balietal_PCA_Functional_Robust}
\@writefile{toc}{\contentsline {section}{\numberline {3}A robust measure of dispersion}{8}{section.3}\protected@file@percent }
\newlabel{Sec:WSDispersion1}{{3}{8}{A robust measure of dispersion}{section.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}The Weighted Sign Covariance Matrix}{8}{subsection.3.1}\protected@file@percent }
\citation{ref:SPL12765_Taskinenetal}
\newlabel{eq:tildeX}{{6}{9}{The Weighted Sign Covariance Matrix}{equation.3.6}{}}
\newlabel{eq:tildeSigma}{{7}{9}{The Weighted Sign Covariance Matrix}{equation.3.7}{}}
\newlabel{Thm:WSVariance}{{3.1}{9}{}{Theorem.3.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}Sample version of $\tilde  \Sigma $}{10}{subsection.3.2}\protected@file@percent }
\newlabel{Lemma:lemma1}{{3.2}{10}{}{Theorem.3.2}{}}
\citation{ref:SPL12765_Taskinenetal}
\citation{ref:AndersonBook09}
\newlabel{Theorem:CLT1}{{3.3}{12}{}{Theorem.3.3}{}}
\newlabel{Theorem:Eigen1}{{3.4}{12}{}{Theorem.3.4}{}}
\newlabel{equation:DevEq}{{8}{12}{}{equation.3.8}{}}
\citation{ref:HuberBook81}
\citation{ref:HuberBook81}
\newlabel{equation:covevEq}{{10}{13}{Sample version of $\tilde \Sigma $}{equation.3.10}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4}An affine equivariant robust measure of dispersion}{13}{section.4}\protected@file@percent }
\newlabel{Sec:WSDispersion2}{{4}{13}{An affine equivariant robust measure of dispersion}{section.4}{}}
\newlabel{eqn:ADCM}{{11}{13}{An affine equivariant robust measure of dispersion}{equation.4.11}{}}
\citation{ref:Biometrika00603_CrouxHaesbroeck}
\newlabel{Thm:Eigen2}{{4.1}{14}{}{Theorem.4.1}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5}Robust estimation of eigenvalues, and a plug-in estimator of $\Sigma $}{14}{section.5}\protected@file@percent }
\newlabel{Sec:Eigen}{{5}{14}{Robust estimation of eigenvalues, and a plug-in estimator of $\Sigma $}{section.5}{}}
\citation{ref:Bernoulli152308_Minsker_Median_Banach}
\newlabel{Thm:pluginSigma}{{5.1}{15}{}{Theorem.5.1}{}}
\citation{ref:HampelBook86}
\citation{ref:JRSSB79217_Sibson}
\citation{ref:Biometrika00603_CrouxHaesbroeck}
\citation{ref:Biometrika00603_CrouxHaesbroeck}
\@writefile{toc}{\contentsline {section}{\numberline {6}Influence Functions of Dispersion Measures}{16}{section.6}\protected@file@percent }
\newlabel{Sec:RE_Dispersion}{{6}{16}{Influence Functions of Dispersion Measures}{section.6}{}}
\newlabel{Thm:IF}{{6.1}{16}{}{Theorem.6.1}{}}
\newlabel{Thm:IF2}{{6.2}{16}{}{Theorem.6.2}{}}
\citation{ref:HampelBook86}
\citation{ref:HuberBook81}
\citation{ref:AoS87234_Tyler}
\citation{ref:LinearAlgebraApplications9281_MiaoBenIsrael}
\newlabel{Thm:IF3}{{6.3}{17}{}{Theorem.6.3}{}}
\@writefile{toc}{\contentsline {section}{\numberline {7}Simulation Studies}{17}{section.7}\protected@file@percent }
\newlabel{Sec:Simulation}{{7}{17}{Simulation Studies}{section.7}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.1}Efficiency of different robust estimators}{17}{subsection.7.1}\protected@file@percent }
\citation{ref:JMVA071611_Sirkiaetal}
\citation{ref:AoS87234_Tyler}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.2}Influence function comparison}{18}{subsection.7.2}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces Finite sample efficiencies of estimators of the first eigenvector based on several scatter matrices in dimension $p=4$. The notation H, M or P after $\tilde  {\Sigma }$ or ${\Sigma }_{*}$ indicates the depth function used for the weights: H = halfspace depth, M = Mahalanobis depth, P = projection depth.\relax }}{19}{table.caption.3}\protected@file@percent }
\newlabel{table:FSEtable4}{{1}{19}{Finite sample efficiencies of estimators of the first eigenvector based on several scatter matrices in dimension $p=4$. The notation H, M or P after $\tilde {\Sigma }$ or ${\Sigma }_{*}$ indicates the depth function used for the weights: H = halfspace depth, M = Mahalanobis depth, P = projection depth.\relax }{table.caption.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.3}Efficiency of affine equivariant robust estimator}{19}{subsection.7.3}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Plot of the norm of influence function for first eigenvector of (a) sample covariance matrix, (b) SCM, (c) Tyler's scatter matrix and $\tilde  {\Sigma }$ for weights obtained from (d) Halfspace depth, (e) Mahalanobis depth, (f) Projection depth for a bivariate normal distribution with ${\boldsymbol  {\mu }}= {\bf  0}, \Sigma = \diag  (2,1)$\relax }}{20}{figure.caption.4}\protected@file@percent }
\newlabel{fig:IFnorm}{{2}{20}{Plot of the norm of influence function for first eigenvector of (a) sample covariance matrix, (b) SCM, (c) Tyler's scatter matrix and $\tilde {\Sigma }$ for weights obtained from (d) Halfspace depth, (e) Mahalanobis depth, (f) Projection depth for a bivariate normal distribution with $\bfmu = {\bf 0}, \Sigma = \diag (2,1)$\relax }{figure.caption.4}{}}
\citation{ref:Sinica10927_Cooketal,ref:PhilTransRoyalSoc094385_AdragniCook,ref:JASA15599_CookZhang}
\citation{ref:PhilTransRoyalSoc094385_AdragniCook}
\@writefile{lot}{\contentsline {table}{\numberline {2}{\ignorespaces Table of AREs of the estimator for the first eigenvector estimation using $\Sigma _{*}$, relative to using the sample covariance matrix, for different choices of dimension $p$. The data-generating distributions are the multivariate Normal (MVN), and multivariate $t$-distributions with degrees of freedom 5, 6, 10, 15 and 25. Weights for $\Sigma _{*}$ are based on either the projection depth (PD) or the half-space depth (HSD).\relax }}{21}{table.caption.5}\protected@file@percent }
\newlabel{table:AREtable}{{2}{21}{Table of AREs of the estimator for the first eigenvector estimation using $\Sigma _{*}$, relative to using the sample covariance matrix, for different choices of dimension $p$. The data-generating distributions are the multivariate Normal (MVN), and multivariate $t$-distributions with degrees of freedom 5, 6, 10, 15 and 25. Weights for $\Sigma _{*}$ are based on either the projection depth (PD) or the half-space depth (HSD).\relax }{table.caption.5}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.4}Robust sufficient dimension reduction and supervised learning}{21}{subsection.7.4}\protected@file@percent }
\citation{ref:PhilTransRoyalSoc094385_AdragniCook}
\citation{ref:PhilTransRoyalSoc094385_AdragniCook}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Average prediction errors for two methods of SDR (a) in absence and (b) in presence of outliers\relax }}{22}{figure.caption.6}\protected@file@percent }
\newlabel{fig:SDRfig}{{3}{22}{Average prediction errors for two methods of SDR (a) in absence and (b) in presence of outliers\relax }{figure.caption.6}{}}
\citation{ref:JASA151100_BoenteSalibianBarrera}
\citation{ref:Technometrics0564_Hubertetal}
\citation{ref:EsbensenetalBook94}
\@writefile{toc}{\contentsline {section}{\numberline {8}Real Data Applications}{23}{section.8}\protected@file@percent }
\newlabel{Sec:DA}{{8}{23}{Real Data Applications}{section.8}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces Actual sample curves, their spline approximations and diagnostic plots respectively for El-Ni\~no (left side plots) and Octane (right side plots) datasets\relax }}{24}{figure.caption.7}\protected@file@percent }
\newlabel{fig:fPCAfig}{{4}{24}{Actual sample curves, their spline approximations and diagnostic plots respectively for El-Ni\~no (left side plots) and Octane (right side plots) datasets\relax }{figure.caption.7}{}}
\bibstyle{apalike}
\bibdata{arxiv-bib}
\bibcite{ref:PhilTransRoyalSoc094385_AdragniCook}{{1}{2009}{{Adragni and Cook}}{{}}}
\bibcite{ref:AndersonBook09}{{2}{2009}{{Anderson}}{{}}}
\bibcite{ref:AoS112852_Balietal_PCA_Functional_Robust}{{3}{2011}{{Bali et~al.}}{{}}}
\@writefile{toc}{\contentsline {section}{\numberline {9}Conclusions}{25}{section.9}\protected@file@percent }
\newlabel{Sec:Conclusion}{{9}{25}{Conclusions}{section.9}{}}
\bibcite{ref:JASA151100_BoenteSalibianBarrera}{{4}{2015}{{Boente and Salibian-Barrera}}{{}}}
\bibcite{ref:AoS17591_Cardotetal_Median_HilbertSpace}{{5}{2017}{{Cardot et~al.}}{{}}}
\bibcite{ref:AoS141203_ChakrabortyChaudhuri_Banach_Quantile}{{6}{2014}{{Chakraborty and Chaudhuri}}{{}}}
\bibcite{ref:CBose_AoS05414}{{7}{2005}{{Chatterjee and Bose}}{{}}}
\bibcite{ref:JASA96862_Chaudhuri}{{8}{1996}{{Chaudhuri}}{{}}}
\bibcite{ref:Sinica10927_Cooketal}{{9}{2010}{{Cook et~al.}}{{}}}
\bibcite{ref:JASA15599_CookZhang}{{10}{2015}{{Cook and Zhang}}{{}}}
\bibcite{ref:Biometrika00603_CrouxHaesbroeck}{{11}{2000}{{Croux and Haesbroeck}}{{}}}
\bibcite{ref:EsbensenetalBook94}{{12}{1994}{{Esbensen et~al.}}{{}}}
\bibcite{ref:Fangetal90_Book}{{13}{1990}{{Fang et~al.}}{{}}}
\bibcite{ref:AoS891631_Haberman}{{14}{1989}{{Haberman}}{{}}}
\bibcite{ref:Biometrika48414_Haldane}{{15}{1948}{{Haldane}}{{}}}
\bibcite{ref:HampelBook86}{{16}{1986}{{Hampel et~al.}}{{}}}
\bibcite{ref:HuberBook81}{{17}{1981}{{Huber}}{{}}}
\bibcite{ref:Technometrics0564_Hubertetal}{{18}{2005}{{Hubert et~al.}}{{}}}
\bibcite{ref:AoS97435_Koltchinskii}{{19}{1997}{{Koltchinskii}}{{}}}
\bibcite{LiuPareliusSingh99}{{20}{1999}{{Liu et~al.}}{{}}}
\bibcite{ref:Test991_Locantoreetal}{{21}{1999}{{Locantore et~al.}}{{}}}
\bibcite{ref:Biometrika14673_MagyarTyler}{{22}{2014}{{Magyar and Tyler}}{{}}}
\bibcite{StatPaper18}{{23}{2018}{{Majumdar and Chatterjee}}{{}}}
\bibcite{ref:LinearAlgebraApplications9281_MiaoBenIsrael}{{24}{1992}{{Miao and Ben-Israel}}{{}}}
\bibcite{ref:Bernoulli152308_Minsker_Median_Banach}{{25}{2015}{{Minsker}}{{}}}
\bibcite{ref:JNonpara95201_MottonenOja95}{{26}{1995}{{M{\"o}tt{\"o}nen and Oja}}{{}}}
\bibcite{ref:AoS921514_Niemiro}{{27}{1992}{{Niemiro}}{{}}}
\bibcite{ref:OjaBook10}{{28}{2010}{{Oja}}{{}}}
\bibcite{ref:DIMACS061_Serfling}{{29}{2006}{{Serfling}}{{}}}
\bibcite{ref:JRSSB79217_Sibson}{{30}{1979}{{Sibson}}{{}}}
\bibcite{ref:JMVA071611_Sirkiaetal}{{31}{2007}{{Sirki{\"a} et~al.}}{{}}}
\bibcite{ref:SPL12765_Taskinenetal}{{32}{2012}{{Taskinen et~al.}}{{}}}
\bibcite{ref:AoS87234_Tyler}{{33}{1987}{{Tyler}}{{}}}
\bibcite{ref:JASA151658_WangPengLi}{{34}{2015}{{Wang et~al.}}{{}}}
\bibcite{ref:AoS00461_ZuoSerfling}{{35}{2000}{{Zuo and Serfling}}{{}}}
\citation{ref:Biometrika14673_MagyarTyler}
\@writefile{toc}{\contentsline {section}{\numberline {A}Form of $V_W$}{28}{appendix.A}\protected@file@percent }
\newlabel{sec:appA}{{A}{28}{Form of $V_W$}{appendix.A}{}}
\newlabel{eqn:VWeqn}{{15}{28}{Form of $V_W$}{equation.A.15}{}}
\@writefile{toc}{\contentsline {paragraph}{}{28}{section*.11}\protected@file@percent }
\citation{ref:JASA151658_WangPengLi}
\citation{ref:JASA151658_WangPengLi}
\citation{ref:AndersonBook09}
\citation{ref:SPL12765_Taskinenetal}
\@writefile{toc}{\contentsline {section}{\numberline {B}Proofs}{29}{appendix.B}\protected@file@percent }
\newlabel{section:appB}{{B}{29}{Proofs}{appendix.B}{}}
\newlabel{lemma:lemmaB1}{{B.1}{29}{}{Theorem.B.1}{}}
\newlabel{lemma:lemmaB2}{{B.2}{29}{}{Theorem.B.2}{}}
\newlabel{Theorem:decomp}{{B.3}{29}{}{Theorem.B.3}{}}
\newlabel{equation:decompEq}{{16}{29}{}{equation.B.16}{}}
\newlabel{equation:app1}{{17}{30}{Proofs}{equation.B.17}{}}
\@writefile{toc}{\contentsline {paragraph}{}{30}{section*.12}\protected@file@percent }
